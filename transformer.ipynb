{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "28d49c11-ff4b-4891-b92b-e33132398101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from firebase_admin import credentials, firestore\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "\n",
    "# Firebase Initialization\n",
    "cred = credentials.Certificate(\"adminkey.json\")\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "# Constants\n",
    "INCLUDE_ONLY = ['Stephen', 'Lillian', 'Ren', 'Yuanheng', 'Ethan Shao', 'z']\n",
    "ACTIVITIES = ['sit', 'walk', 'upstair', 'downstair']\n",
    "TIME_START, TIME_END = 500, 6000  \n",
    "SAMPLING_RATE = 100  # Hz\n",
    "OVERLAP = 0.5  # 50% overlap\n",
    "\n",
    "# Sequence length in seconds for chunking (experiment with values)\n",
    "CHUNK_SIZE = 1\n",
    "\n",
    "# Transformer hyperparams\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "EMB_SIZE = 128\n",
    "NHEAD = 8\n",
    "NHID = 128\n",
    "NLAYERS = 3\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "09f4ea2b-5ce2-473a-a67f-cb509a9f5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(collection_name):\n",
    "    \"\"\"Fetch raw accelerometer data filtered by time and included people.\"\"\"\n",
    "    data_raw, docs = [], []\n",
    "    for person in db.collection(collection_name).stream():\n",
    "        person_name = str(person.to_dict().get('name', ''))\n",
    "        if person_name not in INCLUDE_ONLY:\n",
    "            continue\n",
    "\n",
    "        for activity in ACTIVITIES:\n",
    "            for recording in db.collection(collection_name).document(person_name).collection(activity).stream():\n",
    "                record = recording.to_dict()\n",
    "                if 'acceleration' not in record:\n",
    "                    continue\n",
    "\n",
    "                df = pd.DataFrame(record['acceleration'])\n",
    "                if 'time' in df.columns:\n",
    "                    df = df[(df['time'] >= TIME_START) & (df['time'] <= TIME_END)].drop(columns=['time'])\n",
    "                    data_raw.append(df)\n",
    "                    docs.append({'activity': activity})\n",
    "    return data_raw, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f16f344-9001-4137-a982-f4bf1a2b261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data_raw(data_raw, docs, chunk_size_sec, sampling_rate, overlap=OVERLAP):\n",
    "    \"\"\"Chunk raw acceleration data into overlapping windows with labels.\"\"\"\n",
    "    data, labels = [], []\n",
    "    chunk_samples = int(chunk_size_sec * sampling_rate)\n",
    "    step = int(chunk_samples * (1 - overlap))\n",
    "\n",
    "    for i, df in enumerate(data_raw):\n",
    "        for start in range(0, len(df) - chunk_samples + 1, step):\n",
    "            chunk = df.iloc[start:start + chunk_samples]\n",
    "            if len(chunk) == chunk_samples:\n",
    "                data.append(chunk[['x', 'y', 'z']].values)  # raw accel values, no features\n",
    "                labels.append(ACTIVITIES.index(docs[i]['activity']))\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2bd5b85-c2f1-4375-b65a-c3453236d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size, dropout=0.1, maxlen=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(maxlen, emb_size)\n",
    "        position = torch.arange(0, maxlen, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-math.log(10000.0) / emb_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # shape (1, maxlen, emb_size)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, emb_size)\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "df68393a-b1e3-434f-9596-a25f38d28707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, emb_size=EMB_SIZE, nhead=NHEAD, nhid=NHID, nlayers=NLAYERS, nclasses=len(ACTIVITIES), dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(3, emb_size)  # x,y,z -> emb_size\n",
    "        self.pos_encoder = PositionalEncoding(emb_size, dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=nhid, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=nlayers)\n",
    "        self.classifier = nn.Linear(emb_size, nclasses)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, 3)\n",
    "        x = self.embedding(x) * math.sqrt(self.emb_size)  # (batch, seq_len, emb_size)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.permute(1, 0, 2)  # (seq_len, batch, emb_size)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)  # average pooling over sequence dimension -> (batch, emb_size)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "48505b89-e87c-48ca-a5ac-1648eb61b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate():\n",
    "    # Fetch and chunk data from Firestore\n",
    "    print(\"Fetching training data...\")\n",
    "    training_data_raw, training_docs = fetch_data(\"training\")\n",
    "    print(f\"Fetched {len(training_data_raw)} training raw data entries.\")\n",
    "    print(\"Fetching testing data...\")\n",
    "    testing_data_raw, testing_docs = fetch_data(\"testing\")\n",
    "    print(f\"Fetched {len(testing_data_raw)} testing raw data entries.\")\n",
    "\n",
    "    X_train, y_train = chunk_data_raw(training_data_raw, training_docs, CHUNK_SIZE, SAMPLING_RATE, OVERLAP)\n",
    "    X_test, y_test = chunk_data_raw(testing_data_raw, testing_docs, CHUNK_SIZE, SAMPLING_RATE, OVERLAP)\n",
    "\n",
    "    print(f\"Training chunks: {X_train.shape}, Training labels: {y_train.shape}\")\n",
    "    print(f\"Testing chunks: {X_test.shape}, Testing labels: {y_test.shape}\")\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Dataset and DataLoader\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    test_ds = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = TransformerClassifier().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            predicted = preds.argmax(dim=1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=ACTIVITIES))\n",
    "\n",
    "    # Confusion matrix with seaborn heatmap\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    correct_counts = np.diag(cm)\n",
    "    total_per_class = cm.sum(axis=1)\n",
    "    accuracy_per_class = (correct_counts / total_per_class) * 100\n",
    "    yticklabels_with_acc = [f\"{act} ({accuracy_per_class[i]:.1f}%)\" for i, act in enumerate(ACTIVITIES)]\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Oranges\", xticklabels=ACTIVITIES, yticklabels=yticklabels_with_acc)\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Transformer Model Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e084466-639d-4999-ac41-c9f3b204db28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching training data...\n",
      "Fetched 48 training raw data entries.\n",
      "Fetching testing data...\n",
      "Fetched 48 testing raw data entries.\n",
      "Training chunks: (480, 100, 3), Training labels: (480,)\n",
      "Testing chunks: (480, 100, 3), Testing labels: (480,)\n",
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wenzh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1.1796\n",
      "Epoch 2/100, Loss: 0.8899\n",
      "Epoch 3/100, Loss: 0.7343\n",
      "Epoch 4/100, Loss: 0.6389\n",
      "Epoch 5/100, Loss: 0.5535\n",
      "Epoch 6/100, Loss: 0.5171\n",
      "Epoch 7/100, Loss: 0.4451\n",
      "Epoch 8/100, Loss: 0.4218\n",
      "Epoch 9/100, Loss: 0.3838\n",
      "Epoch 10/100, Loss: 0.3998\n",
      "Epoch 11/100, Loss: 0.3795\n",
      "Epoch 12/100, Loss: 0.3461\n",
      "Epoch 13/100, Loss: 0.3495\n",
      "Epoch 14/100, Loss: 0.2928\n",
      "Epoch 15/100, Loss: 0.2616\n",
      "Epoch 16/100, Loss: 0.2456\n",
      "Epoch 17/100, Loss: 0.2571\n",
      "Epoch 18/100, Loss: 0.2235\n",
      "Epoch 19/100, Loss: 0.2740\n",
      "Epoch 20/100, Loss: 0.2004\n",
      "Epoch 21/100, Loss: 0.2182\n",
      "Epoch 22/100, Loss: 0.2240\n",
      "Epoch 23/100, Loss: 0.2115\n",
      "Epoch 24/100, Loss: 0.2066\n",
      "Epoch 25/100, Loss: 0.2007\n",
      "Epoch 26/100, Loss: 0.2182\n",
      "Epoch 27/100, Loss: 0.1871\n",
      "Epoch 28/100, Loss: 0.1590\n",
      "Epoch 29/100, Loss: 0.1730\n",
      "Epoch 30/100, Loss: 0.2129\n",
      "Epoch 31/100, Loss: 0.2324\n",
      "Epoch 32/100, Loss: 0.1674\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

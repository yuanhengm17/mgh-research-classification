{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30e998e0-f6cd-4d3d-82f0-08637032af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from firebase_admin import credentials, firestore\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Firebase Initialization\n",
    "cred = credentials.Certificate(\"adminkey.json\")\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(filename='training_log.txt', level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Constants\n",
    "INCLUDE_ONLY = ['Stephen', 'Lillian', 'Ren', 'Yuanheng', 'Ethan Shao']\n",
    "ACTIVITIES = ['sit','walk','upstair']\n",
    "CHUNK_SIZE = 2.375  # in seconds (can be a decimal)\n",
    "SAMPLING_RATE = 100  # Hz\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f933bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "OVERLAP = 0.5  # Fix for previous NameError\n",
    "\n",
    "# Define feature extraction function\n",
    "def extract_features(chunk):\n",
    "    \"\"\"Extract features from a chunked acceleration segment with selected statistics.\"\"\"\n",
    "    feature_vector = []\n",
    "    \n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        data_series = pd.Series(chunk[axis])\n",
    "        # Apply smoothing\n",
    "        smoothed_data = data_series.rolling(window=5, min_periods=1).mean()\n",
    "        feature_vector.extend([\n",
    "            smoothed_data.mean(),                  # Mean\n",
    "            smoothed_data.median(),                # Median\n",
    "            smoothed_data.std(),                   # Standard deviation\n",
    "            smoothed_data.var(),                   # Variance\n",
    "            smoothed_data.min(),                   # Minimum\n",
    "            smoothed_data.max(),                   # Maximum\n",
    "        ])\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "287ad27b-8007-4ccd-b113-f8016c2aaec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data \n",
    "def fetch_data_for_stephen(collection_name, activities, time_start=500, time_end=6000):\n",
    "    data, docs = [], []\n",
    "    person_name = \"Stephen\"\n",
    "    \n",
    "    for activity in activities:\n",
    "        for recording in db.collection(collection_name).document(person_name).collection(activity).stream():\n",
    "            record = recording.to_dict()\n",
    "            if 'acceleration' not in record:\n",
    "                continue\n",
    "\n",
    "            docs.append(record)\n",
    "            df = pd.DataFrame(record['acceleration'])\n",
    "            \n",
    "            if 'time' in df.columns:\n",
    "                filtered_df = df[(df['time'] >= time_start) & (df['time'] <= time_end)]\n",
    "                data.append(filtered_df)\n",
    "            else:\n",
    "                raise ValueError(\"The 'acceleration' field must include a 'time' column.\")\n",
    "    return data, docs\n",
    "\n",
    "# Fetch data\n",
    "training_data_raw, training_docs = fetch_data_for_stephen(\"training\", ACTIVITIES)\n",
    "testing_data_raw, testing_docs = fetch_data_for_stephen(\"testing\", ACTIVITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a1284a61-2522-4348-abbf-1d4e31e36bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate\n",
    "\n",
    "overlap = 0.5  \n",
    "\n",
    "def chunk_data_with_overlap(data_raw, docs, chunk_size, activities, sampling_rate, overlap):\n",
    "    data, labels = [], []\n",
    "    activity_distribution = np.zeros(len(activities))\n",
    "    chunk_samples = int(chunk_size * sampling_rate)\n",
    "    step = int(chunk_samples * (1 - overlap))  # compute step size based on overlap\n",
    "\n",
    "    for i in range(len(data_raw)):\n",
    "        total_samples = len(data_raw[i]['x'])\n",
    "        for start in range(0, total_samples - chunk_samples + 1, step):\n",
    "            end = start + chunk_samples\n",
    "            x = list(data_raw[i][\"x\"])[start:end]\n",
    "            y = list(data_raw[i][\"y\"])[start:end]\n",
    "            z = list(data_raw[i][\"z\"])[start:end]\n",
    "            activity = docs[i]['activity']\n",
    "            label = activities.index(activity)\n",
    "\n",
    "            activity_distribution[label] += 1\n",
    "            data.append([x, y, z])  # Shape: (chunk_samples, 3)\n",
    "            labels.append(label)\n",
    "\n",
    "    return data, labels, activity_distribution\n",
    "\n",
    "\n",
    "# Combine raw data and docs\n",
    "all_data_raw = training_data_raw + testing_data_raw\n",
    "all_docs = training_docs + testing_docs\n",
    "\n",
    "# Chunk all data\n",
    "all_data, all_labels, all_distribution = chunk_data_with_overlap(all_data_raw, all_docs, CHUNK_SIZE, ACTIVITIES, SAMPLING_RATE, overlap)\n",
    "\n",
    "# Perform stratified train-test split\n",
    "indices = np.arange(len(all_data))\n",
    "train_indices, test_indices = train_test_split(\n",
    "    indices, test_size=0.2, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "# Split data and labels\n",
    "training_data = [all_data[i] for i in train_indices]\n",
    "training_labels = [all_labels[i] for i in train_indices]\n",
    "testing_data = [all_data[i] for i in test_indices]\n",
    "testing_labels = [all_labels[i] for i in test_indices]\n",
    "\n",
    "# Compute activity distributions\n",
    "training_distribution = np.bincount(training_labels, minlength=len(ACTIVITIES))\n",
    "testing_distribution = np.bincount(testing_labels, minlength=len(ACTIVITIES))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43de7965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset summary:\n",
      "+----------+------------------+\n",
      "| Dataset  | number of chunks |\n",
      "+----------+------------------+\n",
      "| training |        6         |\n",
      "| testing  |        6         |\n",
      "+----------+------------------+\n",
      "Training Activities Count\n",
      "sit: 7 chunks\n",
      "walk: 6 chunks\n",
      "upstair: 6 chunks\n",
      "\n",
      "Testing Activity Count\n",
      "sit:1 chunks\n",
      "walk:2 chunks\n",
      "upstair:2 chunks\n",
      "6\n",
      "6\n",
      "(19, 3, 237)\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate #for table formatting\n",
    "\n",
    "#Calculate the number of training and testing samples\n",
    "num_training_samples = len(training_data_raw)\n",
    "num_testing_samples = len(testing_data_raw)\n",
    "\n",
    "\n",
    "#table\n",
    "summary_table = [[\"training\", num_training_samples], [\"testing\", num_testing_samples]]\n",
    "\n",
    "#print\n",
    "print(\"dataset summary:\")\n",
    "print(tabulate(summary_table, headers = [\"Dataset\", \"number of chunks\"], tablefmt=\"pretty\"))\n",
    "\n",
    "print(\"Training Activities Count\")\n",
    "for i, activity in enumerate(ACTIVITIES):\n",
    "    print(f\"{activity}: {int(training_distribution[i])} chunks\")\n",
    "\n",
    "print(\"\\nTesting Activity Count\")\n",
    "for i, activity in enumerate(ACTIVITIES):\n",
    "    print(f\"{activity}:{int(testing_distribution[i])} chunks\")\n",
    "print(len(training_data_raw))\n",
    "print(len(testing_data_raw))\n",
    "print(np.array(training_data).shape)\n",
    "print(len(training_data_raw))\n",
    "print(len(testing_data_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fae1da3e-3e2c-40ad-82cb-6d090f2cc7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Activity Distribution: [6. 6. 6.]\n",
      "Testing Activity Distribution: [6. 6. 6.]\n"
     ]
    }
   ],
   "source": [
    "# Extract features using chunk_data_with_overlap\n",
    "X_train, y_train, train_distribution = chunk_data_with_overlap(\n",
    "    training_data_raw, training_docs, CHUNK_SIZE, ACTIVITIES, SAMPLING_RATE, OVERLAP\n",
    ")\n",
    "X_test, y_test, test_distribution = chunk_data_with_overlap(\n",
    "    testing_data_raw, testing_docs, CHUNK_SIZE, ACTIVITIES, SAMPLING_RATE, OVERLAP\n",
    ")\n",
    "\n",
    "# Combine train and test for cross-validation\n",
    "X_all = np.concatenate([X_train, X_test], axis=0)  # Shape: (num_chunks, 3, chunk_samples)\n",
    "y_all = np.concatenate([y_train, y_test], axis=0)\n",
    "\n",
    "# Reshape to 2D: (num_chunks, 3 * chunk_samples)\n",
    "n_chunks, n_axes, n_samples = X_all.shape\n",
    "X_all_reshaped = X_all.reshape(n_chunks, n_axes * n_samples)\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_all_scaled = scaler.fit_transform(X_all_reshaped)\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_all = torch.tensor(X_all_scaled, dtype=torch.float32)  # Shape: (n_samples, n_features)\n",
    "y_all = torch.tensor(y_all, dtype=torch.long)\n",
    "\n",
    "print(\"Training Activity Distribution:\", train_distribution)\n",
    "print(\"Testing Activity Distribution:\", test_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7ecb31f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' class OptimizedLSTMModel(nn.Module):\\n    def __init__(self, num_classes, input_channels, seq_length, hidden_size=128, num_layers=2):\\n        super(OptimizedLSTMModel, self).__init__()\\n        self.seq_length = seq_length\\n        self.hidden_size = hidden_size\\n        self.num_layers = num_layers\\n        \\n        # LSTM layer expects input of shape (batch_size, seq_length, input_size)\\n        self.lstm = nn.LSTM(input_channels, hidden_size, num_layers, batch_first=True)\\n        \\n        # Fully connected layer to output predictions\\n        self.fc = nn.Linear(hidden_size, num_classes)\\n        \\n        # Dropout layer for regularization\\n        self.dropout = nn.Dropout(0.3)\\n\\n    def forward(self, x):\\n        # LSTM requires a hidden state and cell state to be initialized\\n        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\\n        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\\n\\n        # Pass through LSTM\\n        out, _ = self.lstm(x, (h0, c0))\\n\\n        # Use the output of the last timestep for classification\\n        out = out[:, -1, :]  # Take the last hidden state\\n        out = self.dropout(out)\\n        \\n        # Pass through the fully connected layer\\n        out = self.fc(out)\\n        return out\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' class OptimizedLSTMModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels, seq_length, hidden_size=128, num_layers=2):\n",
    "        super(OptimizedLSTMModel, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer expects input of shape (batch_size, seq_length, input_size)\n",
    "        self.lstm = nn.LSTM(input_channels, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer to output predictions\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # LSTM requires a hidden state and cell state to be initialized\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Use the output of the last timestep for classification\n",
    "        out = out[:, -1, :]  # Take the last hidden state\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        # Pass through the fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ec68f8d-85ff-48e1-b219-a547e9393c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for extracted features (MLP)\n",
    "class FeatureModel(nn.Module):\n",
    "    def __init__(self, num_classes, input_features=18):\n",
    "        super(FeatureModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_features, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2fea2d82-2721-4226-87c8-d0386cb60e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to save best model and metadata\n",
    "BEST_MODEL_PATH = \"best_model.pth\"\n",
    "BEST_METADATA_PATH = \"best_model.json\"\n",
    "\n",
    "# Corrected save_best_model function\n",
    "def save_best_model(epoch, model, optimizer, loss, accuracy, train_losses, test_losses):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "    }\n",
    "    torch.save(checkpoint, BEST_MODEL_PATH)\n",
    "\n",
    "    # Save metadata with correct variable names\n",
    "    with open(BEST_METADATA_PATH, \"w\") as f:\n",
    "        json.dump({\"epoch\": epoch, \"test_loss\": loss, \"test_accuracy\": accuracy}, f)\n",
    "\n",
    "# Function to load best model if exists\n",
    "def load_best_model(model, optimizer, best_model_path=BEST_MODEL_PATH):\n",
    "    if os.path.exists(best_model_path):\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        \n",
    "        # Print checkpoint keys to understand its structure\n",
    "        print(\"Checkpoint keys:\", checkpoint.keys())\n",
    "        \n",
    "        # Load model weights\n",
    "        model_state_dict = model.state_dict()\n",
    "        checkpoint_state_dict = checkpoint['model_state_dict']\n",
    "        \n",
    "        # Filter out incompatible keys\n",
    "        filtered_checkpoint_state_dict = {k: v for k, v in checkpoint_state_dict.items() if k in model_state_dict}\n",
    "        model_state_dict.update(filtered_checkpoint_state_dict)\n",
    "        model.load_state_dict(model_state_dict)\n",
    "        \n",
    "        # Load other metadata if available\n",
    "        start_epoch = checkpoint.get('epoch', 0)\n",
    "        best_loss = checkpoint.get('loss', float('inf'))  # Default to infinity if loss is missing\n",
    "        best_avg_accuracy = checkpoint.get('accuracy', 0)  # Default to 0 if accuracy is missing\n",
    "        \n",
    "        # If train_losses and test_losses aren't saved, return empty lists or placeholders\n",
    "        train_losses = checkpoint.get('train_losses', [])\n",
    "        test_losses = checkpoint.get('test_losses', [])\n",
    "        \n",
    "        return start_epoch, best_loss, best_avg_accuracy, train_losses, test_losses\n",
    "    else:\n",
    "        print(\"No checkpoint found, starting from scratch.\")\n",
    "        # Return default values\n",
    "        return 0, float('inf'), 0, [], []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "afb6cc02-f6d5-441e-8ea1-736efc276305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model (no transpose for MLP)\n",
    "def evaluate_model(loader, model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in loader:\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "01254ebf-d89d-4173-9f04-ba08155090cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from torch.optim import Adam\n",
    "\n",
    "# Data Augmentation Functions\n",
    "def add_jitter(batch_X, noise_level=0.01):\n",
    "    noise = torch.randn_like(batch_X) * noise_level\n",
    "    return batch_X + noise\n",
    "\n",
    "def scale_signal(batch_X, scale_range=(0.9, 1.1)):\n",
    "    scale_factor = torch.FloatTensor(batch_X.shape[0], 1, 1).uniform_(*scale_range)\n",
    "    return batch_X * scale_factor\n",
    "\n",
    "def time_warp(batch_X, sigma=0.2):\n",
    "    batch_size, num_channels, seq_length = batch_X.shape\n",
    "    time_steps = np.arange(seq_length)\n",
    "    warping_curve = np.cumsum(np.random.normal(0, sigma, size=(batch_size, seq_length)), axis=1)\n",
    "    warping_curve = (warping_curve - warping_curve.min(axis=1, keepdims=True)) / \\\n",
    "                    (warping_curve.max(axis=1, keepdims=True) - warping_curve.min(axis=1, keepdims=True)) * seq_length\n",
    "    warped_X = torch.zeros_like(batch_X)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(num_channels):\n",
    "            f = interp1d(time_steps, batch_X[i, j, :].cpu().numpy(), kind='linear', fill_value='extrapolate')\n",
    "            warped_X[i, j, :] = torch.tensor(f(warping_curve[i]), dtype=batch_X.dtype)\n",
    "    return warped_X\n",
    "\n",
    "def random_crop(batch_X, crop_size=0.9, target_length=None):\n",
    "    batch_size, num_channels, seq_length = batch_X.shape\n",
    "    new_length = int(seq_length * crop_size)\n",
    "    start_idx = torch.randint(0, seq_length - new_length + 1, (batch_size,))\n",
    "    cropped_X = torch.zeros(batch_size, num_channels, new_length)\n",
    "    for i in range(batch_size):\n",
    "        cropped_X[i] = batch_X[i, :, start_idx[i]:start_idx[i] + new_length]\n",
    "    \n",
    "    if target_length is not None:\n",
    "        if new_length < target_length:\n",
    "            padding = torch.zeros(batch_size, num_channels, target_length - new_length)\n",
    "            cropped_X = torch.cat([cropped_X, padding], dim=2)\n",
    "        elif new_length > target_length:\n",
    "            cropped_X = cropped_X[:, :, :target_length]\n",
    "    return cropped_X\n",
    "\n",
    "def permute_segments(batch_X, num_segments=5):\n",
    "    batch_size, num_channels, seq_length = batch_X.shape\n",
    "    segment_length = seq_length // num_segments\n",
    "    permuted_X = batch_X.clone()\n",
    "    for i in range(batch_size):\n",
    "        perm = torch.randperm(num_segments)\n",
    "        for j in range(num_segments):\n",
    "            permuted_X[i, :, j * segment_length:(j + 1) * segment_length] = \\\n",
    "                batch_X[i, :, perm[j] * segment_length:(perm[j] + 1) * segment_length]\n",
    "    return permuted_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fc68f1f4-225f-455c-b6d0-80a76a3ce598",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureModel(num_classes=NUM_CLASSES, input_features=18)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.02, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=50, min_lr=1e-5)\n",
    "\n",
    "# Initialize training variables\n",
    "start_epoch = 0\n",
    "best_loss = float('inf')\n",
    "best_avg_accuracy = 0.0\n",
    "train_losses = []\n",
    "test_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd628c08-376b-468a-ab5f-6c1a88c7587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Fold 1 Epoch [1/100], Train Loss: 0.8583, Train Acc: 78.57%, Test Loss: 1.0773, Test Acc: 25.00%\n",
      "Fold 1 Epoch [2/100], Train Loss: 0.7088, Train Acc: 78.57%, Test Loss: 1.0033, Test Acc: 25.00%\n",
      "Fold 1 Epoch [3/100], Train Loss: 0.5792, Train Acc: 89.29%, Test Loss: 0.9485, Test Acc: 50.00%\n",
      "Fold 1 Epoch [4/100], Train Loss: 0.4788, Train Acc: 92.86%, Test Loss: 0.9055, Test Acc: 62.50%\n",
      "Fold 1 Epoch [5/100], Train Loss: 0.3971, Train Acc: 92.86%, Test Loss: 0.8691, Test Acc: 62.50%\n",
      "Fold 1 Epoch [6/100], Train Loss: 0.3317, Train Acc: 92.86%, Test Loss: 0.8358, Test Acc: 62.50%\n",
      "Fold 1 Epoch [7/100], Train Loss: 0.2778, Train Acc: 92.86%, Test Loss: 0.8026, Test Acc: 62.50%\n",
      "Fold 1 Epoch [8/100], Train Loss: 0.2328, Train Acc: 96.43%, Test Loss: 0.7689, Test Acc: 62.50%\n",
      "Fold 1 Epoch [9/100], Train Loss: 0.1954, Train Acc: 96.43%, Test Loss: 0.7343, Test Acc: 62.50%\n",
      "Fold 1 Epoch [10/100], Train Loss: 0.1645, Train Acc: 96.43%, Test Loss: 0.7001, Test Acc: 62.50%\n",
      "Fold 1 Epoch [11/100], Train Loss: 0.1382, Train Acc: 96.43%, Test Loss: 0.6641, Test Acc: 62.50%\n",
      "Fold 1 Epoch [12/100], Train Loss: 0.1156, Train Acc: 100.00%, Test Loss: 0.6280, Test Acc: 62.50%\n",
      "Fold 1 Epoch [13/100], Train Loss: 0.0958, Train Acc: 100.00%, Test Loss: 0.5872, Test Acc: 75.00%\n",
      "Fold 1 Epoch [14/100], Train Loss: 0.0786, Train Acc: 100.00%, Test Loss: 0.5471, Test Acc: 75.00%\n",
      "Fold 1 Epoch [15/100], Train Loss: 0.0636, Train Acc: 100.00%, Test Loss: 0.5083, Test Acc: 75.00%\n",
      "Fold 1 Epoch [16/100], Train Loss: 0.0511, Train Acc: 100.00%, Test Loss: 0.4715, Test Acc: 75.00%\n",
      "Fold 1 Epoch [17/100], Train Loss: 0.0408, Train Acc: 100.00%, Test Loss: 0.4383, Test Acc: 75.00%\n",
      "Fold 1 Epoch [18/100], Train Loss: 0.0324, Train Acc: 100.00%, Test Loss: 0.4065, Test Acc: 75.00%\n",
      "Fold 1 Epoch [19/100], Train Loss: 0.0256, Train Acc: 100.00%, Test Loss: 0.3777, Test Acc: 87.50%\n",
      "Fold 1 Epoch [20/100], Train Loss: 0.0205, Train Acc: 100.00%, Test Loss: 0.3514, Test Acc: 87.50%\n",
      "Fold 1 Epoch [21/100], Train Loss: 0.0164, Train Acc: 100.00%, Test Loss: 0.3286, Test Acc: 87.50%\n",
      "Fold 1 Epoch [22/100], Train Loss: 0.0131, Train Acc: 100.00%, Test Loss: 0.3084, Test Acc: 87.50%\n",
      "Fold 1 Epoch [23/100], Train Loss: 0.0106, Train Acc: 100.00%, Test Loss: 0.2906, Test Acc: 87.50%\n",
      "Fold 1 Epoch [24/100], Train Loss: 0.0087, Train Acc: 100.00%, Test Loss: 0.2745, Test Acc: 87.50%\n",
      "Fold 1 Epoch [25/100], Train Loss: 0.0071, Train Acc: 100.00%, Test Loss: 0.2603, Test Acc: 87.50%\n",
      "Fold 1 Epoch [26/100], Train Loss: 0.0059, Train Acc: 100.00%, Test Loss: 0.2481, Test Acc: 87.50%\n",
      "Fold 1 Epoch [27/100], Train Loss: 0.0049, Train Acc: 100.00%, Test Loss: 0.2377, Test Acc: 87.50%\n",
      "Fold 1 Epoch [28/100], Train Loss: 0.0041, Train Acc: 100.00%, Test Loss: 0.2284, Test Acc: 87.50%\n",
      "Fold 1 Epoch [29/100], Train Loss: 0.0035, Train Acc: 100.00%, Test Loss: 0.2200, Test Acc: 87.50%\n",
      "Fold 1 Epoch [30/100], Train Loss: 0.0030, Train Acc: 100.00%, Test Loss: 0.2125, Test Acc: 87.50%\n",
      "Fold 1 Epoch [31/100], Train Loss: 0.0026, Train Acc: 100.00%, Test Loss: 0.2059, Test Acc: 87.50%\n",
      "Fold 1 Epoch [32/100], Train Loss: 0.0022, Train Acc: 100.00%, Test Loss: 0.1998, Test Acc: 87.50%\n",
      "Fold 1 Epoch [33/100], Train Loss: 0.0019, Train Acc: 100.00%, Test Loss: 0.1946, Test Acc: 87.50%\n",
      "Fold 1 Epoch [34/100], Train Loss: 0.0017, Train Acc: 100.00%, Test Loss: 0.1900, Test Acc: 87.50%\n",
      "Fold 1 Epoch [35/100], Train Loss: 0.0015, Train Acc: 100.00%, Test Loss: 0.1864, Test Acc: 87.50%\n",
      "Fold 1 Epoch [36/100], Train Loss: 0.0013, Train Acc: 100.00%, Test Loss: 0.1834, Test Acc: 87.50%\n",
      "Fold 1 Epoch [37/100], Train Loss: 0.0012, Train Acc: 100.00%, Test Loss: 0.1804, Test Acc: 87.50%\n",
      "Fold 1 Epoch [38/100], Train Loss: 0.0011, Train Acc: 100.00%, Test Loss: 0.1781, Test Acc: 87.50%\n",
      "Fold 1 Epoch [39/100], Train Loss: 0.0010, Train Acc: 100.00%, Test Loss: 0.1761, Test Acc: 87.50%\n",
      "Fold 1 Epoch [40/100], Train Loss: 0.0009, Train Acc: 100.00%, Test Loss: 0.1742, Test Acc: 87.50%\n",
      "Fold 1 Epoch [41/100], Train Loss: 0.0008, Train Acc: 100.00%, Test Loss: 0.1723, Test Acc: 87.50%\n",
      "Fold 1 Epoch [42/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.1706, Test Acc: 87.50%\n",
      "Fold 1 Epoch [43/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.1693, Test Acc: 87.50%\n",
      "Fold 1 Epoch [44/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.1687, Test Acc: 87.50%\n",
      "Fold 1 Epoch [45/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.1683, Test Acc: 87.50%\n",
      "Fold 1 Epoch [46/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.1681, Test Acc: 87.50%\n",
      "Fold 1 Epoch [47/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.1680, Test Acc: 87.50%\n",
      "Fold 1 Epoch [48/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.1678, Test Acc: 87.50%\n",
      "Fold 1 Epoch [49/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.1675, Test Acc: 87.50%\n",
      "Fold 1 Epoch [50/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.1672, Test Acc: 87.50%\n",
      "Fold 1 Epoch [51/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.1668, Test Acc: 87.50%\n",
      "Fold 1 Epoch [52/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.1670, Test Acc: 87.50%\n",
      "Fold 1 Epoch [53/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.1672, Test Acc: 87.50%\n",
      "Fold 1 Epoch [54/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.1673, Test Acc: 87.50%\n",
      "Fold 1 Epoch [55/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1670, Test Acc: 87.50%\n",
      "Fold 1 Epoch [56/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1667, Test Acc: 87.50%\n",
      "Fold 1 Epoch [57/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1665, Test Acc: 87.50%\n",
      "Fold 1 Epoch [58/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1663, Test Acc: 87.50%\n",
      "Fold 1 Epoch [59/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1663, Test Acc: 87.50%\n",
      "Fold 1 Epoch [60/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1664, Test Acc: 87.50%\n",
      "Fold 1 Epoch [61/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1669, Test Acc: 87.50%\n",
      "Fold 1 Epoch [62/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.1673, Test Acc: 87.50%\n",
      "Fold 1 Epoch [63/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1681, Test Acc: 87.50%\n",
      "Fold 1 Epoch [64/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1688, Test Acc: 87.50%\n",
      "Fold 1 Epoch [65/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1695, Test Acc: 87.50%\n",
      "Fold 1 Epoch [66/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1703, Test Acc: 87.50%\n",
      "Fold 1 Epoch [67/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1711, Test Acc: 87.50%\n",
      "Fold 1 Epoch [68/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1722, Test Acc: 87.50%\n",
      "Fold 1 Epoch [69/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1730, Test Acc: 87.50%\n",
      "Fold 1 Epoch [70/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1739, Test Acc: 87.50%\n",
      "Fold 1 Epoch [71/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1747, Test Acc: 87.50%\n",
      "Fold 1 Epoch [72/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1752, Test Acc: 87.50%\n",
      "Fold 1 Epoch [73/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1754, Test Acc: 87.50%\n",
      "Fold 1 Epoch [74/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1756, Test Acc: 87.50%\n",
      "Fold 1 Epoch [75/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1758, Test Acc: 87.50%\n",
      "Fold 1 Epoch [76/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1762, Test Acc: 87.50%\n",
      "Fold 1 Epoch [77/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1765, Test Acc: 87.50%\n",
      "Fold 1 Epoch [78/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1767, Test Acc: 87.50%\n",
      "Fold 1 Epoch [79/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.1768, Test Acc: 87.50%\n",
      "Fold 1 Epoch [80/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1769, Test Acc: 87.50%\n",
      "Fold 1 Epoch [81/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1771, Test Acc: 87.50%\n",
      "Fold 1 Epoch [82/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1769, Test Acc: 87.50%\n",
      "Fold 1 Epoch [83/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1768, Test Acc: 87.50%\n",
      "Fold 1 Epoch [84/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1767, Test Acc: 87.50%\n",
      "Fold 1 Epoch [85/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1766, Test Acc: 87.50%\n",
      "Fold 1 Epoch [86/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1765, Test Acc: 87.50%\n",
      "Fold 1 Epoch [87/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1763, Test Acc: 87.50%\n",
      "Fold 1 Epoch [88/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1761, Test Acc: 87.50%\n",
      "Fold 1 Epoch [89/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1760, Test Acc: 87.50%\n",
      "Fold 1 Epoch [90/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1759, Test Acc: 87.50%\n",
      "Fold 1 Epoch [91/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1757, Test Acc: 87.50%\n",
      "Fold 1 Epoch [92/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1753, Test Acc: 87.50%\n",
      "Fold 1 Epoch [93/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1749, Test Acc: 87.50%\n",
      "Fold 1 Epoch [94/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1746, Test Acc: 87.50%\n",
      "Fold 1 Epoch [95/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1745, Test Acc: 87.50%\n",
      "Fold 1 Epoch [96/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1744, Test Acc: 87.50%\n",
      "Fold 1 Epoch [97/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1739, Test Acc: 87.50%\n",
      "Fold 1 Epoch [98/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1735, Test Acc: 87.50%\n",
      "Fold 1 Epoch [99/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1725, Test Acc: 87.50%\n",
      "Fold 1 Epoch [100/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.1716, Test Acc: 87.50%\n",
      "Fold 1 Best Accuracy: 87.50%\n",
      "Fold 2/5\n",
      "Fold 2 Epoch [1/100], Train Loss: 0.8806, Train Acc: 82.76%, Test Loss: 0.9033, Test Acc: 71.43%\n",
      "Fold 2 Epoch [2/100], Train Loss: 0.7165, Train Acc: 100.00%, Test Loss: 0.7408, Test Acc: 100.00%\n",
      "Fold 2 Epoch [3/100], Train Loss: 0.5934, Train Acc: 100.00%, Test Loss: 0.6176, Test Acc: 100.00%\n",
      "Fold 2 Epoch [4/100], Train Loss: 0.5022, Train Acc: 93.10%, Test Loss: 0.5215, Test Acc: 100.00%\n",
      "Fold 2 Epoch [5/100], Train Loss: 0.4303, Train Acc: 93.10%, Test Loss: 0.4437, Test Acc: 100.00%\n",
      "Fold 2 Epoch [6/100], Train Loss: 0.3705, Train Acc: 93.10%, Test Loss: 0.3773, Test Acc: 100.00%\n",
      "Fold 2 Epoch [7/100], Train Loss: 0.3197, Train Acc: 93.10%, Test Loss: 0.3196, Test Acc: 100.00%\n",
      "Fold 2 Epoch [8/100], Train Loss: 0.2771, Train Acc: 96.55%, Test Loss: 0.2715, Test Acc: 100.00%\n",
      "Fold 2 Epoch [9/100], Train Loss: 0.2400, Train Acc: 96.55%, Test Loss: 0.2310, Test Acc: 100.00%\n",
      "Fold 2 Epoch [10/100], Train Loss: 0.2071, Train Acc: 96.55%, Test Loss: 0.1968, Test Acc: 100.00%\n",
      "Fold 2 Epoch [11/100], Train Loss: 0.1785, Train Acc: 96.55%, Test Loss: 0.1683, Test Acc: 100.00%\n",
      "Fold 2 Epoch [12/100], Train Loss: 0.1538, Train Acc: 96.55%, Test Loss: 0.1438, Test Acc: 100.00%\n",
      "Fold 2 Epoch [13/100], Train Loss: 0.1322, Train Acc: 96.55%, Test Loss: 0.1233, Test Acc: 100.00%\n",
      "Fold 2 Epoch [14/100], Train Loss: 0.1136, Train Acc: 100.00%, Test Loss: 0.1057, Test Acc: 100.00%\n",
      "Fold 2 Epoch [15/100], Train Loss: 0.0974, Train Acc: 100.00%, Test Loss: 0.0909, Test Acc: 100.00%\n",
      "Fold 2 Epoch [16/100], Train Loss: 0.0837, Train Acc: 100.00%, Test Loss: 0.0778, Test Acc: 100.00%\n",
      "Fold 2 Epoch [17/100], Train Loss: 0.0721, Train Acc: 100.00%, Test Loss: 0.0663, Test Acc: 100.00%\n",
      "Fold 2 Epoch [18/100], Train Loss: 0.0622, Train Acc: 100.00%, Test Loss: 0.0563, Test Acc: 100.00%\n",
      "Fold 2 Epoch [19/100], Train Loss: 0.0537, Train Acc: 100.00%, Test Loss: 0.0479, Test Acc: 100.00%\n",
      "Fold 2 Epoch [20/100], Train Loss: 0.0469, Train Acc: 100.00%, Test Loss: 0.0405, Test Acc: 100.00%\n",
      "Fold 2 Epoch [21/100], Train Loss: 0.0412, Train Acc: 100.00%, Test Loss: 0.0342, Test Acc: 100.00%\n",
      "Fold 2 Epoch [22/100], Train Loss: 0.0362, Train Acc: 100.00%, Test Loss: 0.0288, Test Acc: 100.00%\n",
      "Fold 2 Epoch [23/100], Train Loss: 0.0318, Train Acc: 100.00%, Test Loss: 0.0241, Test Acc: 100.00%\n",
      "Fold 2 Epoch [24/100], Train Loss: 0.0281, Train Acc: 100.00%, Test Loss: 0.0203, Test Acc: 100.00%\n",
      "Fold 2 Epoch [25/100], Train Loss: 0.0247, Train Acc: 100.00%, Test Loss: 0.0170, Test Acc: 100.00%\n",
      "Fold 2 Epoch [26/100], Train Loss: 0.0218, Train Acc: 100.00%, Test Loss: 0.0143, Test Acc: 100.00%\n",
      "Fold 2 Epoch [27/100], Train Loss: 0.0193, Train Acc: 100.00%, Test Loss: 0.0122, Test Acc: 100.00%\n",
      "Fold 2 Epoch [28/100], Train Loss: 0.0170, Train Acc: 100.00%, Test Loss: 0.0104, Test Acc: 100.00%\n",
      "Fold 2 Epoch [29/100], Train Loss: 0.0151, Train Acc: 100.00%, Test Loss: 0.0089, Test Acc: 100.00%\n",
      "Fold 2 Epoch [30/100], Train Loss: 0.0134, Train Acc: 100.00%, Test Loss: 0.0077, Test Acc: 100.00%\n",
      "Fold 2 Epoch [31/100], Train Loss: 0.0120, Train Acc: 100.00%, Test Loss: 0.0066, Test Acc: 100.00%\n",
      "Fold 2 Epoch [32/100], Train Loss: 0.0107, Train Acc: 100.00%, Test Loss: 0.0058, Test Acc: 100.00%\n",
      "Fold 2 Epoch [33/100], Train Loss: 0.0096, Train Acc: 100.00%, Test Loss: 0.0050, Test Acc: 100.00%\n",
      "Fold 2 Epoch [34/100], Train Loss: 0.0086, Train Acc: 100.00%, Test Loss: 0.0044, Test Acc: 100.00%\n",
      "Fold 2 Epoch [35/100], Train Loss: 0.0077, Train Acc: 100.00%, Test Loss: 0.0039, Test Acc: 100.00%\n",
      "Fold 2 Epoch [36/100], Train Loss: 0.0069, Train Acc: 100.00%, Test Loss: 0.0035, Test Acc: 100.00%\n",
      "Fold 2 Epoch [37/100], Train Loss: 0.0063, Train Acc: 100.00%, Test Loss: 0.0031, Test Acc: 100.00%\n",
      "Fold 2 Epoch [38/100], Train Loss: 0.0056, Train Acc: 100.00%, Test Loss: 0.0028, Test Acc: 100.00%\n",
      "Fold 2 Epoch [39/100], Train Loss: 0.0051, Train Acc: 100.00%, Test Loss: 0.0025, Test Acc: 100.00%\n",
      "Fold 2 Epoch [40/100], Train Loss: 0.0046, Train Acc: 100.00%, Test Loss: 0.0022, Test Acc: 100.00%\n",
      "Fold 2 Epoch [41/100], Train Loss: 0.0042, Train Acc: 100.00%, Test Loss: 0.0020, Test Acc: 100.00%\n",
      "Fold 2 Epoch [42/100], Train Loss: 0.0038, Train Acc: 100.00%, Test Loss: 0.0018, Test Acc: 100.00%\n",
      "Fold 2 Epoch [43/100], Train Loss: 0.0035, Train Acc: 100.00%, Test Loss: 0.0017, Test Acc: 100.00%\n",
      "Fold 2 Epoch [44/100], Train Loss: 0.0032, Train Acc: 100.00%, Test Loss: 0.0015, Test Acc: 100.00%\n",
      "Fold 2 Epoch [45/100], Train Loss: 0.0030, Train Acc: 100.00%, Test Loss: 0.0014, Test Acc: 100.00%\n",
      "Fold 2 Epoch [46/100], Train Loss: 0.0027, Train Acc: 100.00%, Test Loss: 0.0013, Test Acc: 100.00%\n",
      "Fold 2 Epoch [47/100], Train Loss: 0.0025, Train Acc: 100.00%, Test Loss: 0.0012, Test Acc: 100.00%\n",
      "Fold 2 Epoch [48/100], Train Loss: 0.0023, Train Acc: 100.00%, Test Loss: 0.0011, Test Acc: 100.00%\n",
      "Fold 2 Epoch [49/100], Train Loss: 0.0022, Train Acc: 100.00%, Test Loss: 0.0011, Test Acc: 100.00%\n",
      "Fold 2 Epoch [50/100], Train Loss: 0.0020, Train Acc: 100.00%, Test Loss: 0.0010, Test Acc: 100.00%\n",
      "Fold 2 Epoch [51/100], Train Loss: 0.0019, Train Acc: 100.00%, Test Loss: 0.0009, Test Acc: 100.00%\n",
      "Fold 2 Epoch [52/100], Train Loss: 0.0017, Train Acc: 100.00%, Test Loss: 0.0009, Test Acc: 100.00%\n",
      "Fold 2 Epoch [53/100], Train Loss: 0.0016, Train Acc: 100.00%, Test Loss: 0.0008, Test Acc: 100.00%\n",
      "Fold 2 Epoch [54/100], Train Loss: 0.0015, Train Acc: 100.00%, Test Loss: 0.0008, Test Acc: 100.00%\n",
      "Fold 2 Epoch [55/100], Train Loss: 0.0014, Train Acc: 100.00%, Test Loss: 0.0007, Test Acc: 100.00%\n",
      "Fold 2 Epoch [56/100], Train Loss: 0.0013, Train Acc: 100.00%, Test Loss: 0.0007, Test Acc: 100.00%\n",
      "Fold 2 Epoch [57/100], Train Loss: 0.0012, Train Acc: 100.00%, Test Loss: 0.0006, Test Acc: 100.00%\n",
      "Fold 2 Epoch [58/100], Train Loss: 0.0012, Train Acc: 100.00%, Test Loss: 0.0006, Test Acc: 100.00%\n",
      "Fold 2 Epoch [59/100], Train Loss: 0.0011, Train Acc: 100.00%, Test Loss: 0.0006, Test Acc: 100.00%\n",
      "Fold 2 Epoch [60/100], Train Loss: 0.0010, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 2 Epoch [61/100], Train Loss: 0.0010, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 2 Epoch [62/100], Train Loss: 0.0009, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 2 Epoch [63/100], Train Loss: 0.0009, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 2 Epoch [64/100], Train Loss: 0.0008, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 2 Epoch [65/100], Train Loss: 0.0008, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 2 Epoch [66/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 2 Epoch [67/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 2 Epoch [68/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 2 Epoch [69/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 2 Epoch [70/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [71/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [72/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [73/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [74/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [75/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [76/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [77/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [78/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [79/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 2 Epoch [80/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [81/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [82/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [83/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [84/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [85/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [86/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [87/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [88/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [89/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [90/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [91/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [92/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [93/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [94/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [95/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [96/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [97/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [98/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [99/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Epoch [100/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 2 Best Accuracy: 100.00%\n",
      "Fold 3/5\n",
      "Fold 3 Epoch [1/100], Train Loss: 0.8672, Train Acc: 89.66%, Test Loss: 0.8700, Test Acc: 100.00%\n",
      "Fold 3 Epoch [2/100], Train Loss: 0.7305, Train Acc: 100.00%, Test Loss: 0.7171, Test Acc: 100.00%\n",
      "Fold 3 Epoch [3/100], Train Loss: 0.6031, Train Acc: 100.00%, Test Loss: 0.5841, Test Acc: 100.00%\n",
      "Fold 3 Epoch [4/100], Train Loss: 0.4905, Train Acc: 100.00%, Test Loss: 0.4792, Test Acc: 85.71%\n",
      "Fold 3 Epoch [5/100], Train Loss: 0.3944, Train Acc: 100.00%, Test Loss: 0.3985, Test Acc: 85.71%\n",
      "Fold 3 Epoch [6/100], Train Loss: 0.3127, Train Acc: 100.00%, Test Loss: 0.3348, Test Acc: 85.71%\n",
      "Fold 3 Epoch [7/100], Train Loss: 0.2459, Train Acc: 100.00%, Test Loss: 0.2874, Test Acc: 85.71%\n",
      "Fold 3 Epoch [8/100], Train Loss: 0.1928, Train Acc: 100.00%, Test Loss: 0.2542, Test Acc: 85.71%\n",
      "Fold 3 Epoch [9/100], Train Loss: 0.1511, Train Acc: 100.00%, Test Loss: 0.2330, Test Acc: 85.71%\n",
      "Fold 3 Epoch [10/100], Train Loss: 0.1184, Train Acc: 100.00%, Test Loss: 0.2198, Test Acc: 85.71%\n",
      "Fold 3 Epoch [11/100], Train Loss: 0.0928, Train Acc: 100.00%, Test Loss: 0.2119, Test Acc: 85.71%\n",
      "Fold 3 Epoch [12/100], Train Loss: 0.0727, Train Acc: 100.00%, Test Loss: 0.2080, Test Acc: 85.71%\n",
      "Fold 3 Epoch [13/100], Train Loss: 0.0568, Train Acc: 100.00%, Test Loss: 0.2066, Test Acc: 85.71%\n",
      "Fold 3 Epoch [14/100], Train Loss: 0.0441, Train Acc: 100.00%, Test Loss: 0.2065, Test Acc: 85.71%\n",
      "Fold 3 Epoch [15/100], Train Loss: 0.0341, Train Acc: 100.00%, Test Loss: 0.2070, Test Acc: 85.71%\n",
      "Fold 3 Epoch [16/100], Train Loss: 0.0260, Train Acc: 100.00%, Test Loss: 0.2078, Test Acc: 85.71%\n",
      "Fold 3 Epoch [17/100], Train Loss: 0.0199, Train Acc: 100.00%, Test Loss: 0.2088, Test Acc: 85.71%\n",
      "Fold 3 Epoch [18/100], Train Loss: 0.0154, Train Acc: 100.00%, Test Loss: 0.2106, Test Acc: 85.71%\n",
      "Fold 3 Epoch [19/100], Train Loss: 0.0118, Train Acc: 100.00%, Test Loss: 0.2122, Test Acc: 85.71%\n",
      "Fold 3 Epoch [20/100], Train Loss: 0.0092, Train Acc: 100.00%, Test Loss: 0.2137, Test Acc: 85.71%\n",
      "Fold 3 Epoch [21/100], Train Loss: 0.0072, Train Acc: 100.00%, Test Loss: 0.2150, Test Acc: 85.71%\n",
      "Fold 3 Epoch [22/100], Train Loss: 0.0056, Train Acc: 100.00%, Test Loss: 0.2156, Test Acc: 85.71%\n",
      "Fold 3 Epoch [23/100], Train Loss: 0.0044, Train Acc: 100.00%, Test Loss: 0.2159, Test Acc: 85.71%\n",
      "Fold 3 Epoch [24/100], Train Loss: 0.0035, Train Acc: 100.00%, Test Loss: 0.2163, Test Acc: 85.71%\n",
      "Fold 3 Epoch [25/100], Train Loss: 0.0028, Train Acc: 100.00%, Test Loss: 0.2166, Test Acc: 85.71%\n",
      "Fold 3 Epoch [26/100], Train Loss: 0.0022, Train Acc: 100.00%, Test Loss: 0.2167, Test Acc: 85.71%\n",
      "Fold 3 Epoch [27/100], Train Loss: 0.0018, Train Acc: 100.00%, Test Loss: 0.2167, Test Acc: 85.71%\n",
      "Fold 3 Epoch [28/100], Train Loss: 0.0015, Train Acc: 100.00%, Test Loss: 0.2163, Test Acc: 85.71%\n",
      "Fold 3 Epoch [29/100], Train Loss: 0.0012, Train Acc: 100.00%, Test Loss: 0.2156, Test Acc: 85.71%\n",
      "Fold 3 Epoch [30/100], Train Loss: 0.0010, Train Acc: 100.00%, Test Loss: 0.2150, Test Acc: 85.71%\n",
      "Fold 3 Epoch [31/100], Train Loss: 0.0009, Train Acc: 100.00%, Test Loss: 0.2146, Test Acc: 85.71%\n",
      "Fold 3 Epoch [32/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.2141, Test Acc: 85.71%\n",
      "Fold 3 Epoch [33/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.2135, Test Acc: 85.71%\n",
      "Fold 3 Epoch [34/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.2125, Test Acc: 85.71%\n",
      "Fold 3 Epoch [35/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.2119, Test Acc: 85.71%\n",
      "Fold 3 Epoch [36/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.2114, Test Acc: 85.71%\n",
      "Fold 3 Epoch [37/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.2110, Test Acc: 85.71%\n",
      "Fold 3 Epoch [38/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.2112, Test Acc: 85.71%\n",
      "Fold 3 Epoch [39/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.2113, Test Acc: 85.71%\n",
      "Fold 3 Epoch [40/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.2114, Test Acc: 85.71%\n",
      "Fold 3 Epoch [41/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.2115, Test Acc: 85.71%\n",
      "Fold 3 Epoch [42/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.2120, Test Acc: 85.71%\n",
      "Fold 3 Epoch [43/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.2124, Test Acc: 85.71%\n",
      "Fold 3 Epoch [44/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.2128, Test Acc: 85.71%\n",
      "Fold 3 Epoch [45/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.2130, Test Acc: 85.71%\n",
      "Fold 3 Epoch [46/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.2133, Test Acc: 85.71%\n",
      "Fold 3 Epoch [47/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.2170, Test Acc: 85.71%\n",
      "Fold 3 Epoch [48/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2202, Test Acc: 85.71%\n",
      "Fold 3 Epoch [49/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2232, Test Acc: 85.71%\n",
      "Fold 3 Epoch [50/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2261, Test Acc: 85.71%\n",
      "Fold 3 Epoch [51/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2287, Test Acc: 85.71%\n",
      "Fold 3 Epoch [52/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2311, Test Acc: 85.71%\n",
      "Fold 3 Epoch [53/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2332, Test Acc: 85.71%\n",
      "Fold 3 Epoch [54/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2352, Test Acc: 85.71%\n",
      "Fold 3 Epoch [55/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2372, Test Acc: 85.71%\n",
      "Fold 3 Epoch [56/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2389, Test Acc: 85.71%\n",
      "Fold 3 Epoch [57/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2404, Test Acc: 85.71%\n",
      "Fold 3 Epoch [58/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2418, Test Acc: 85.71%\n",
      "Fold 3 Epoch [59/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2430, Test Acc: 85.71%\n",
      "Fold 3 Epoch [60/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2439, Test Acc: 85.71%\n",
      "Fold 3 Epoch [61/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2451, Test Acc: 85.71%\n",
      "Fold 3 Epoch [62/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2461, Test Acc: 85.71%\n",
      "Fold 3 Epoch [63/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2471, Test Acc: 85.71%\n",
      "Fold 3 Epoch [64/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2478, Test Acc: 85.71%\n",
      "Fold 3 Epoch [65/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2483, Test Acc: 85.71%\n",
      "Fold 3 Epoch [66/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2492, Test Acc: 85.71%\n",
      "Fold 3 Epoch [67/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2499, Test Acc: 85.71%\n",
      "Fold 3 Epoch [68/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2510, Test Acc: 85.71%\n",
      "Fold 3 Epoch [69/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2519, Test Acc: 85.71%\n",
      "Fold 3 Epoch [70/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2528, Test Acc: 85.71%\n",
      "Fold 3 Epoch [71/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2536, Test Acc: 85.71%\n",
      "Fold 3 Epoch [72/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2544, Test Acc: 85.71%\n",
      "Fold 3 Epoch [73/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2555, Test Acc: 85.71%\n",
      "Fold 3 Epoch [74/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2566, Test Acc: 85.71%\n",
      "Fold 3 Epoch [75/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2576, Test Acc: 85.71%\n",
      "Fold 3 Epoch [76/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2586, Test Acc: 85.71%\n",
      "Fold 3 Epoch [77/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2595, Test Acc: 85.71%\n",
      "Fold 3 Epoch [78/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2603, Test Acc: 85.71%\n",
      "Fold 3 Epoch [79/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2611, Test Acc: 85.71%\n",
      "Fold 3 Epoch [80/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2616, Test Acc: 85.71%\n",
      "Fold 3 Epoch [81/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.2622, Test Acc: 85.71%\n",
      "Fold 3 Epoch [82/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2631, Test Acc: 85.71%\n",
      "Fold 3 Epoch [83/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2641, Test Acc: 85.71%\n",
      "Fold 3 Epoch [84/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2649, Test Acc: 85.71%\n",
      "Fold 3 Epoch [85/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2656, Test Acc: 85.71%\n",
      "Fold 3 Epoch [86/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2670, Test Acc: 85.71%\n",
      "Fold 3 Epoch [87/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2685, Test Acc: 85.71%\n",
      "Fold 3 Epoch [88/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2699, Test Acc: 85.71%\n",
      "Fold 3 Epoch [89/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2718, Test Acc: 85.71%\n",
      "Fold 3 Epoch [90/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2734, Test Acc: 85.71%\n",
      "Fold 3 Epoch [91/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2749, Test Acc: 85.71%\n",
      "Fold 3 Epoch [92/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2762, Test Acc: 85.71%\n",
      "Fold 3 Epoch [93/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2774, Test Acc: 85.71%\n",
      "Fold 3 Epoch [94/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2826, Test Acc: 85.71%\n",
      "Fold 3 Epoch [95/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2873, Test Acc: 85.71%\n",
      "Fold 3 Epoch [96/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2915, Test Acc: 85.71%\n",
      "Fold 3 Epoch [97/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2954, Test Acc: 85.71%\n",
      "Fold 3 Epoch [98/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.2988, Test Acc: 85.71%\n",
      "Fold 3 Epoch [99/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.3019, Test Acc: 85.71%\n",
      "Fold 3 Epoch [100/100], Train Loss: 0.0000, Train Acc: 100.00%, Test Loss: 0.3049, Test Acc: 85.71%\n",
      "Fold 3 Best Accuracy: 100.00%\n",
      "Fold 4/5\n",
      "Fold 4 Epoch [1/100], Train Loss: 0.8850, Train Acc: 79.31%, Test Loss: 0.8126, Test Acc: 100.00%\n",
      "Fold 4 Epoch [2/100], Train Loss: 0.7641, Train Acc: 89.66%, Test Loss: 0.6656, Test Acc: 100.00%\n",
      "Fold 4 Epoch [3/100], Train Loss: 0.6636, Train Acc: 93.10%, Test Loss: 0.5633, Test Acc: 100.00%\n",
      "Fold 4 Epoch [4/100], Train Loss: 0.5730, Train Acc: 93.10%, Test Loss: 0.4787, Test Acc: 100.00%\n",
      "Fold 4 Epoch [5/100], Train Loss: 0.4898, Train Acc: 96.55%, Test Loss: 0.4045, Test Acc: 100.00%\n",
      "Fold 4 Epoch [6/100], Train Loss: 0.4134, Train Acc: 96.55%, Test Loss: 0.3407, Test Acc: 100.00%\n",
      "Fold 4 Epoch [7/100], Train Loss: 0.3435, Train Acc: 96.55%, Test Loss: 0.2842, Test Acc: 100.00%\n",
      "Fold 4 Epoch [8/100], Train Loss: 0.2813, Train Acc: 96.55%, Test Loss: 0.2344, Test Acc: 100.00%\n",
      "Fold 4 Epoch [9/100], Train Loss: 0.2274, Train Acc: 96.55%, Test Loss: 0.1903, Test Acc: 100.00%\n",
      "Fold 4 Epoch [10/100], Train Loss: 0.1815, Train Acc: 96.55%, Test Loss: 0.1525, Test Acc: 100.00%\n",
      "Fold 4 Epoch [11/100], Train Loss: 0.1429, Train Acc: 96.55%, Test Loss: 0.1204, Test Acc: 100.00%\n",
      "Fold 4 Epoch [12/100], Train Loss: 0.1115, Train Acc: 96.55%, Test Loss: 0.0934, Test Acc: 100.00%\n",
      "Fold 4 Epoch [13/100], Train Loss: 0.0864, Train Acc: 100.00%, Test Loss: 0.0718, Test Acc: 100.00%\n",
      "Fold 4 Epoch [14/100], Train Loss: 0.0670, Train Acc: 100.00%, Test Loss: 0.0551, Test Acc: 100.00%\n",
      "Fold 4 Epoch [15/100], Train Loss: 0.0522, Train Acc: 100.00%, Test Loss: 0.0424, Test Acc: 100.00%\n",
      "Fold 4 Epoch [16/100], Train Loss: 0.0407, Train Acc: 100.00%, Test Loss: 0.0325, Test Acc: 100.00%\n",
      "Fold 4 Epoch [17/100], Train Loss: 0.0317, Train Acc: 100.00%, Test Loss: 0.0248, Test Acc: 100.00%\n",
      "Fold 4 Epoch [18/100], Train Loss: 0.0250, Train Acc: 100.00%, Test Loss: 0.0191, Test Acc: 100.00%\n",
      "Fold 4 Epoch [19/100], Train Loss: 0.0199, Train Acc: 100.00%, Test Loss: 0.0148, Test Acc: 100.00%\n",
      "Fold 4 Epoch [20/100], Train Loss: 0.0157, Train Acc: 100.00%, Test Loss: 0.0115, Test Acc: 100.00%\n",
      "Fold 4 Epoch [21/100], Train Loss: 0.0124, Train Acc: 100.00%, Test Loss: 0.0091, Test Acc: 100.00%\n",
      "Fold 4 Epoch [22/100], Train Loss: 0.0099, Train Acc: 100.00%, Test Loss: 0.0073, Test Acc: 100.00%\n",
      "Fold 4 Epoch [23/100], Train Loss: 0.0080, Train Acc: 100.00%, Test Loss: 0.0059, Test Acc: 100.00%\n",
      "Fold 4 Epoch [24/100], Train Loss: 0.0065, Train Acc: 100.00%, Test Loss: 0.0048, Test Acc: 100.00%\n",
      "Fold 4 Epoch [25/100], Train Loss: 0.0053, Train Acc: 100.00%, Test Loss: 0.0040, Test Acc: 100.00%\n",
      "Fold 4 Epoch [26/100], Train Loss: 0.0044, Train Acc: 100.00%, Test Loss: 0.0034, Test Acc: 100.00%\n",
      "Fold 4 Epoch [27/100], Train Loss: 0.0036, Train Acc: 100.00%, Test Loss: 0.0029, Test Acc: 100.00%\n",
      "Fold 4 Epoch [28/100], Train Loss: 0.0031, Train Acc: 100.00%, Test Loss: 0.0025, Test Acc: 100.00%\n",
      "Fold 4 Epoch [29/100], Train Loss: 0.0026, Train Acc: 100.00%, Test Loss: 0.0022, Test Acc: 100.00%\n",
      "Fold 4 Epoch [30/100], Train Loss: 0.0022, Train Acc: 100.00%, Test Loss: 0.0019, Test Acc: 100.00%\n",
      "Fold 4 Epoch [31/100], Train Loss: 0.0019, Train Acc: 100.00%, Test Loss: 0.0017, Test Acc: 100.00%\n",
      "Fold 4 Epoch [32/100], Train Loss: 0.0016, Train Acc: 100.00%, Test Loss: 0.0015, Test Acc: 100.00%\n",
      "Fold 4 Epoch [33/100], Train Loss: 0.0014, Train Acc: 100.00%, Test Loss: 0.0013, Test Acc: 100.00%\n",
      "Fold 4 Epoch [34/100], Train Loss: 0.0013, Train Acc: 100.00%, Test Loss: 0.0012, Test Acc: 100.00%\n",
      "Fold 4 Epoch [35/100], Train Loss: 0.0011, Train Acc: 100.00%, Test Loss: 0.0011, Test Acc: 100.00%\n",
      "Fold 4 Epoch [36/100], Train Loss: 0.0010, Train Acc: 100.00%, Test Loss: 0.0010, Test Acc: 100.00%\n",
      "Fold 4 Epoch [37/100], Train Loss: 0.0009, Train Acc: 100.00%, Test Loss: 0.0009, Test Acc: 100.00%\n",
      "Fold 4 Epoch [38/100], Train Loss: 0.0008, Train Acc: 100.00%, Test Loss: 0.0008, Test Acc: 100.00%\n",
      "Fold 4 Epoch [39/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.0008, Test Acc: 100.00%\n",
      "Fold 4 Epoch [40/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0007, Test Acc: 100.00%\n",
      "Fold 4 Epoch [41/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0007, Test Acc: 100.00%\n",
      "Fold 4 Epoch [42/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0006, Test Acc: 100.00%\n",
      "Fold 4 Epoch [43/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0006, Test Acc: 100.00%\n",
      "Fold 4 Epoch [44/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0006, Test Acc: 100.00%\n",
      "Fold 4 Epoch [45/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 4 Epoch [46/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 4 Epoch [47/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 4 Epoch [48/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 4 Epoch [49/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [50/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [51/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [52/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [53/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [54/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [55/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [56/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 4 Epoch [57/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [58/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [59/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [60/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [61/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [62/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [63/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [64/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [65/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [66/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [67/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [68/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [69/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [70/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [71/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [72/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [73/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 4 Epoch [74/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [75/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [76/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [77/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [78/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [79/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [80/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [81/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [82/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [83/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [84/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [85/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [86/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [87/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [88/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [89/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [90/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [91/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [92/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [93/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [94/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [95/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [96/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [97/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [98/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [99/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Epoch [100/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 4 Best Accuracy: 100.00%\n",
      "Fold 5/5\n",
      "Fold 5 Epoch [1/100], Train Loss: 0.8843, Train Acc: 100.00%, Test Loss: 0.8288, Test Acc: 100.00%\n",
      "Fold 5 Epoch [2/100], Train Loss: 0.7228, Train Acc: 100.00%, Test Loss: 0.6379, Test Acc: 100.00%\n",
      "Fold 5 Epoch [3/100], Train Loss: 0.5864, Train Acc: 100.00%, Test Loss: 0.4807, Test Acc: 100.00%\n",
      "Fold 5 Epoch [4/100], Train Loss: 0.4770, Train Acc: 96.55%, Test Loss: 0.3540, Test Acc: 100.00%\n",
      "Fold 5 Epoch [5/100], Train Loss: 0.3915, Train Acc: 96.55%, Test Loss: 0.2564, Test Acc: 100.00%\n",
      "Fold 5 Epoch [6/100], Train Loss: 0.3255, Train Acc: 96.55%, Test Loss: 0.1837, Test Acc: 100.00%\n",
      "Fold 5 Epoch [7/100], Train Loss: 0.2732, Train Acc: 96.55%, Test Loss: 0.1326, Test Acc: 100.00%\n",
      "Fold 5 Epoch [8/100], Train Loss: 0.2305, Train Acc: 96.55%, Test Loss: 0.0968, Test Acc: 100.00%\n",
      "Fold 5 Epoch [9/100], Train Loss: 0.1954, Train Acc: 96.55%, Test Loss: 0.0712, Test Acc: 100.00%\n",
      "Fold 5 Epoch [10/100], Train Loss: 0.1660, Train Acc: 96.55%, Test Loss: 0.0525, Test Acc: 100.00%\n",
      "Fold 5 Epoch [11/100], Train Loss: 0.1410, Train Acc: 96.55%, Test Loss: 0.0387, Test Acc: 100.00%\n",
      "Fold 5 Epoch [12/100], Train Loss: 0.1204, Train Acc: 96.55%, Test Loss: 0.0284, Test Acc: 100.00%\n",
      "Fold 5 Epoch [13/100], Train Loss: 0.1028, Train Acc: 96.55%, Test Loss: 0.0208, Test Acc: 100.00%\n",
      "Fold 5 Epoch [14/100], Train Loss: 0.0877, Train Acc: 96.55%, Test Loss: 0.0152, Test Acc: 100.00%\n",
      "Fold 5 Epoch [15/100], Train Loss: 0.0749, Train Acc: 96.55%, Test Loss: 0.0111, Test Acc: 100.00%\n",
      "Fold 5 Epoch [16/100], Train Loss: 0.0640, Train Acc: 100.00%, Test Loss: 0.0081, Test Acc: 100.00%\n",
      "Fold 5 Epoch [17/100], Train Loss: 0.0544, Train Acc: 100.00%, Test Loss: 0.0059, Test Acc: 100.00%\n",
      "Fold 5 Epoch [18/100], Train Loss: 0.0463, Train Acc: 100.00%, Test Loss: 0.0043, Test Acc: 100.00%\n",
      "Fold 5 Epoch [19/100], Train Loss: 0.0394, Train Acc: 100.00%, Test Loss: 0.0031, Test Acc: 100.00%\n",
      "Fold 5 Epoch [20/100], Train Loss: 0.0335, Train Acc: 100.00%, Test Loss: 0.0023, Test Acc: 100.00%\n",
      "Fold 5 Epoch [21/100], Train Loss: 0.0282, Train Acc: 100.00%, Test Loss: 0.0017, Test Acc: 100.00%\n",
      "Fold 5 Epoch [22/100], Train Loss: 0.0237, Train Acc: 100.00%, Test Loss: 0.0013, Test Acc: 100.00%\n",
      "Fold 5 Epoch [23/100], Train Loss: 0.0200, Train Acc: 100.00%, Test Loss: 0.0010, Test Acc: 100.00%\n",
      "Fold 5 Epoch [24/100], Train Loss: 0.0169, Train Acc: 100.00%, Test Loss: 0.0008, Test Acc: 100.00%\n",
      "Fold 5 Epoch [25/100], Train Loss: 0.0143, Train Acc: 100.00%, Test Loss: 0.0006, Test Acc: 100.00%\n",
      "Fold 5 Epoch [26/100], Train Loss: 0.0122, Train Acc: 100.00%, Test Loss: 0.0005, Test Acc: 100.00%\n",
      "Fold 5 Epoch [27/100], Train Loss: 0.0104, Train Acc: 100.00%, Test Loss: 0.0004, Test Acc: 100.00%\n",
      "Fold 5 Epoch [28/100], Train Loss: 0.0089, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 5 Epoch [29/100], Train Loss: 0.0077, Train Acc: 100.00%, Test Loss: 0.0003, Test Acc: 100.00%\n",
      "Fold 5 Epoch [30/100], Train Loss: 0.0066, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 5 Epoch [31/100], Train Loss: 0.0057, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 5 Epoch [32/100], Train Loss: 0.0049, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 5 Epoch [33/100], Train Loss: 0.0043, Train Acc: 100.00%, Test Loss: 0.0002, Test Acc: 100.00%\n",
      "Fold 5 Epoch [34/100], Train Loss: 0.0037, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [35/100], Train Loss: 0.0033, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [36/100], Train Loss: 0.0029, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [37/100], Train Loss: 0.0025, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [38/100], Train Loss: 0.0022, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [39/100], Train Loss: 0.0020, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [40/100], Train Loss: 0.0018, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [41/100], Train Loss: 0.0016, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [42/100], Train Loss: 0.0014, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [43/100], Train Loss: 0.0013, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [44/100], Train Loss: 0.0012, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [45/100], Train Loss: 0.0011, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [46/100], Train Loss: 0.0010, Train Acc: 100.00%, Test Loss: 0.0001, Test Acc: 100.00%\n",
      "Fold 5 Epoch [47/100], Train Loss: 0.0009, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [48/100], Train Loss: 0.0009, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [49/100], Train Loss: 0.0008, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [50/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [51/100], Train Loss: 0.0007, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [52/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [53/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [54/100], Train Loss: 0.0006, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [55/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [56/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [57/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [58/100], Train Loss: 0.0005, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [59/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [60/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [61/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [62/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [63/100], Train Loss: 0.0004, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [64/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [65/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [66/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [67/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [68/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [69/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [70/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [71/100], Train Loss: 0.0003, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [72/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [73/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [74/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [75/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [76/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [77/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [78/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [79/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [80/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [81/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [82/100], Train Loss: 0.0002, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [83/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [84/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [85/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [86/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [87/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [88/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [89/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [90/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [91/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [92/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [93/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [94/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [95/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [96/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [97/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [98/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [99/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Epoch [100/100], Train Loss: 0.0001, Train Acc: 100.00%, Test Loss: 0.0000, Test Acc: 100.00%\n",
      "Fold 5 Best Accuracy: 100.00%\n",
      "\n",
      "5-Fold CV Results:\n",
      "Average Accuracy: 97.50% (±5.00)\n",
      "Fold Accuracies: ['87.50%', '100.00%', '100.00%', '100.00%', '100.00%']\n"
     ]
    }
   ],
   "source": [
    "# Get correct input feature count\n",
    "input_features = X_all.shape[1]\n",
    "\n",
    "# Cross-validation setup\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "fold_accuracies = []\n",
    "fold_losses = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X_all)):\n",
    "    print(f'Fold {fold + 1}/{n_folds}')\n",
    "    \n",
    "    # Split data\n",
    "    X_train_fold = X_all[train_idx]\n",
    "    y_train_fold = y_all[train_idx]\n",
    "    X_test_fold = X_all[test_idx]\n",
    "    y_test_fold = y_all[test_idx]\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_dataset = TensorDataset(X_train_fold, y_train_fold)\n",
    "    test_dataset = TensorDataset(X_test_fold, y_test_fold)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    # Initialize model with correct input size\n",
    "    model = FeatureModel(num_classes=NUM_CLASSES, input_features=input_features)\n",
    "    optimizer = Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-4)\n",
    "    \n",
    "    # Training loop\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_accuracy = 0\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        train_loss, train_accuracy = evaluate_model(train_loader, model, criterion)\n",
    "        test_loss, test_accuracy = evaluate_model(test_loader, model, criterion)\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        log_message = (f\"Fold {fold+1} Epoch [{epoch+1}/100], \"\n",
    "                      f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
    "                      f\"Test Loss: {test_loss:.4f}, Test Acc: {test_accuracy:.2f}%\")\n",
    "        logging.info(log_message)\n",
    "        print(log_message)\n",
    "        \n",
    "        if test_accuracy > best_test_accuracy:\n",
    "            best_test_accuracy = test_accuracy\n",
    "            best_test_loss = test_loss\n",
    "            save_best_model(epoch, model, optimizer, test_loss, test_accuracy, train_losses, test_losses)\n",
    "    \n",
    "    fold_accuracies.append(best_test_accuracy)\n",
    "    fold_losses.append(best_test_loss)\n",
    "    print(f'Fold {fold + 1} Best Accuracy: {best_test_accuracy:.2f}%')\n",
    "    \n",
    "# Print summary\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "print(f'\\n5-Fold CV Results:')\n",
    "print(f'Average Accuracy: {mean_accuracy:.2f}% (±{std_accuracy:.2f})')\n",
    "print(f'Fold Accuracies: {[f\"{acc:.2f}%\" for acc in fold_accuracies]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6c79cb82-164f-4ed0-ba0b-63dcc6f6bbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "chunk_sizes = [\n",
    "    0.25, 0.5, 1.0, 1.375, 2.75, 5.5\n",
    "]\n",
    "# Activities for the Confusion matrix\n",
    "ACTIVITIES = ['sit', 'walk','upstair']\n",
    "\n",
    "# Model evaluation (confusion matrix)\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Loop through the test loader to collect predictions and true labels\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(batch_y.cpu().numpy())\n",
    "\n",
    "# Compute the confusion matrix, explicitly specifying the labels\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions, labels=[0, 1, 2]) \n",
    "\n",
    "# Assuming conf_matrix and ACTIVITIES are already defined\n",
    "class_accuracies = np.diag(conf_matrix) / np.sum(conf_matrix, axis=1)  # Compute per-class accuracy\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=ACTIVITIES)\n",
    "fig, ax = plt.subplots()\n",
    "disp.plot(cmap=plt.cm.Blues, ax=ax)\n",
    "\n",
    "# Add per-class accuracy text\n",
    "for i, activity in enumerate(ACTIVITIES):\n",
    "    acc_text = f\"{class_accuracies[i] * 100:.2f}%\"\n",
    "    ax.text(\n",
    "        len(ACTIVITIES) + 0.3, i, acc_text, \n",
    "        fontsize=12, verticalalignment='center', color='black'\n",
    "    )\n",
    "\n",
    "plt.title(\"Confusion Matrix for Activities with Per-Class Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ff91bf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LSTM Results Summary:\n",
      " Chunk Size (s)  Accuracy (%)\n",
      "          0.250          87.5\n",
      "          0.500         100.0\n",
      "          1.000         100.0\n",
      "          1.375         100.0\n",
      "          2.750         100.0\n"
     ]
    }
   ],
   "source": [
    "min_length = min(len(chunk_sizes), len(fold_accuracies))\n",
    "chunk_sizes = chunk_sizes[:min_length]\n",
    "fold_accuracies = fold_accuracies[:min_length]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(chunk_sizes, fold_accuracies, 'bo-')\n",
    "plt.xlabel('Chunk Size (seconds)')\n",
    "plt.ylabel('Test Accuracy (%)')\n",
    "plt.title('LSTM Model Accuracy vs Chunk Size')\n",
    "plt.grid(True)\n",
    "\n",
    "# Add accuracy values as text\n",
    "for x, y in zip(chunk_sizes, fold_accuracies):\n",
    "    plt.text(x, y, f'{y:.1f}', ha='center', va='bottom')\n",
    "\n",
    "plt.savefig('lstm_chunk_size_vs_accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "# Print results table\n",
    "results = pd.DataFrame({\n",
    "    'Chunk Size (s)': chunk_sizes,\n",
    "    'Accuracy (%)': fold_accuracies\n",
    "})\n",
    "print(\"\\nLSTM Results Summary:\")\n",
    "print(results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d0f841cd-23c7-425c-a8c0-6e363b2c94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "incorrect_samples = []\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)  # Get raw logits\n",
    "        probabilities = F.softmax(outputs, dim=1)  # Convert to probabilities\n",
    "        predicted_labels = torch.argmax(probabilities, dim=1)  # Get predicted class\n",
    "        confidence_scores = torch.max(probabilities, dim=1).values  # Get max confidence\n",
    "\n",
    "        # Find incorrect predictions\n",
    "        incorrect_indices = (predicted_labels != batch_y)\n",
    "        for i in range(len(batch_y)):\n",
    "            if incorrect_indices[i]:\n",
    "                incorrect_samples.append({\n",
    "                    \"True Label\": batch_y[i].item(),\n",
    "                    \"Predicted Label\": predicted_labels[i].item(),\n",
    "                    \"Confidence\": confidence_scores[i].item(),\n",
    "                    \"Probabilities\": probabilities[i].tolist()\n",
    "                })\n",
    "\n",
    "# Print results\n",
    "for sample in incorrect_samples:\n",
    "    print(f\"True Label: {sample['True Label']}, Predicted: {sample['Predicted Label']}, Confidence: {sample['Confidence']:.4f}\")\n",
    "    print(f\"Full Probabilities: {sample['Probabilities']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5e8554-cc92-4315-a317-edeb8c823675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

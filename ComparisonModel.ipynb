{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28d49c11-ff4b-4891-b92b-e33132398101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import firebase_admin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from firebase_admin import credentials, firestore\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# Firebase Initialization\n",
    "cred = credentials.Certificate(\"adminkey.json\")\n",
    "#firebase_admin.initialize_app(cred)\n",
    "db = firestore.client()\n",
    "\n",
    "# Constants\n",
    "INCLUDE_ONLY = ['11111']\n",
    "ACTIVITIES = ['sit', 'walk', 'upstairs']\n",
    "SAMPLING_RATE = 100  # Hz\n",
    "OVERLAP = 0.5\n",
    "CHUNK_SIZE = 1  # seconds\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "EMB_SIZE = 128\n",
    "NHEAD = 8\n",
    "NHID = 128\n",
    "NLAYERS = 3\n",
    "DROPOUT = 0.1\n",
    "DIFF_THRESHOLD = 35  # percent difference threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09f4ea2b-5ce2-473a-a67f-cb509a9f5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_by_treatment(treatment_filter):\n",
    "    \"\"\"Fetch data for a specific treatment ('BeforeTreatment' or 'AfterTreatment').\"\"\"\n",
    "    data_raw, docs = [], []\n",
    "\n",
    "    data_ref = db.collection(\"data\")\n",
    "    treatment_doc = data_ref.document(treatment_filter)\n",
    "\n",
    "    for patient_id in INCLUDE_ONLY:\n",
    "        print(f\"Patient: {patient_id}\")\n",
    "        subject_ref = treatment_doc.collection(patient_id)\n",
    "\n",
    "        for activity in ACTIVITIES:\n",
    "            activity_ref = subject_ref.document(activity)\n",
    "            phone_location_col = activity_ref.collections()\n",
    "\n",
    "            for phone_location in phone_location_col:\n",
    "                location_name = phone_location.id\n",
    "                print(f\"  Activity: {activity}, Phone Location: {location_name}\")\n",
    "\n",
    "                for recording in phone_location.stream():\n",
    "                    record = recording.to_dict()\n",
    "                    if 'acceleration' not in record:\n",
    "                        continue\n",
    "\n",
    "                    df = pd.DataFrame(record['acceleration'])\n",
    "                    timestamps = df['timestamp']\n",
    "                    min_time = timestamps.min()\n",
    "                    max_time = timestamps.max()\n",
    "\n",
    "                    df = df[(timestamps >= min_time + 2500) & (timestamps <= max_time - 2500)]\n",
    "                    if df.empty:\n",
    "                        continue\n",
    "\n",
    "                    combined = pd.DataFrame({\n",
    "                        'ax': df['accelerometer'].apply(lambda x: x['x']),\n",
    "                        'ay': df['accelerometer'].apply(lambda x: x['y']),\n",
    "                        'az': df['accelerometer'].apply(lambda x: x['z']),\n",
    "                        'gx': df['gyroscope'].apply(lambda x: x['x']),\n",
    "                        'gy': df['gyroscope'].apply(lambda x: x['y']),\n",
    "                        'gz': df['gyroscope'].apply(lambda x: x['z']),\n",
    "                    })\n",
    "\n",
    "                    data_raw.append(combined)\n",
    "                    docs.append({'activity': activity})\n",
    "\n",
    "    return data_raw, docs\n",
    "\n",
    "def chunk_data_raw(data_raw, docs, chunk_size_sec, sampling_rate, overlap=OVERLAP):\n",
    "    data, labels = [], []\n",
    "    chunk_samples = int(chunk_size_sec * sampling_rate)\n",
    "    step = int(chunk_samples * (1 - overlap))\n",
    "\n",
    "    for i, df in enumerate(data_raw):\n",
    "        for start in range(0, len(df) - chunk_samples + 1, step):\n",
    "            chunk = df.iloc[start:start + chunk_samples]\n",
    "            if len(chunk) == chunk_samples:\n",
    "                data.append(chunk.values)\n",
    "                labels.append(ACTIVITIES.index(docs[i]['activity']))\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2bd5b85-c2f1-4375-b65a-c3453236d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size, dropout=0.1, maxlen=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        pe = torch.zeros(maxlen, emb_size)\n",
    "        position = torch.arange(0, maxlen, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-math.log(10000.0) / emb_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df68393a-b1e3-434f-9596-a25f38d28707",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=6, emb_size=EMB_SIZE, nhead=NHEAD, nhid=NHID, nlayers=NLAYERS, nclasses=len(ACTIVITIES), dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(input_dim, emb_size)\n",
    "        self.pos_encoder = PositionalEncoding(emb_size, dropout)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=nhid, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=nlayers)\n",
    "        self.classifier = nn.Linear(emb_size, nclasses)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x) * math.sqrt(self.emb_size)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48505b89-e87c-48ca-a5ac-1648eb61b779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_before_after():\n",
    "    print(\"Fetching BeforeTreatment data...\")\n",
    "    data_before, docs_before = fetch_data_by_treatment('BeforeTreatment')\n",
    "    X_train, y_train = chunk_data_raw(data_before, docs_before, CHUNK_SIZE, SAMPLING_RATE, OVERLAP)\n",
    "\n",
    "    print(\"Fetching AfterTreatment data...\")\n",
    "    data_after, docs_after = fetch_data_by_treatment('AfterTreatment')\n",
    "    X_test, y_test = chunk_data_raw(data_after, docs_after, CHUNK_SIZE, SAMPLING_RATE, OVERLAP)\n",
    "\n",
    "    print(f\"Train data: {X_train.shape}, Test data: {X_test.shape}\")\n",
    "\n",
    "    # Convert to tensors\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    train_ds = TensorDataset(X_train, y_train)\n",
    "    test_ds = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = TransformerClassifier().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "    # Training\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0, 0, 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            correct += (preds.argmax(dim=1) == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "        scheduler.step()\n",
    "\n",
    "        train_acc = correct / total * 100\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "\n",
    "    # Evaluate on test (AfterTreatment)\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            correct += (preds.argmax(dim=1) == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "            all_preds.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "            all_labels.extend(yb.cpu().numpy())\n",
    "\n",
    "    test_acc = correct / total * 100\n",
    "    print(f\"\\nTest Accuracy (AfterTreatment): {test_acc:.2f}%\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=ACTIVITIES))\n",
    "\n",
    "    # Compare train vs test\n",
    "    acc_diff = abs(train_acc - test_acc)\n",
    "    if acc_diff >= DIFF_THRESHOLD:\n",
    "        print(f\"Train-Test accuracy differs by {acc_diff:.2f}%, which exceeds threshold of {DIFF_THRESHOLD}%. Data is different before vs after.\")\n",
    "    else:\n",
    "        print(f\"Train-Test accuracy differs by only {acc_diff:.2f}%, within threshold of {DIFF_THRESHOLD}%. Data is similar before vs after.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e084466-639d-4999-ac41-c9f3b204db28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching BeforeTreatment data...\n",
      "Patient: 11111\n",
      "  Activity: sit, Phone Location: DominantWrist\n",
      "  Activity: walk, Phone Location: DominantWrist\n",
      "  Activity: upstairs, Phone Location: DominantWrist\n",
      "Fetching AfterTreatment data...\n",
      "Patient: 11111\n",
      "  Activity: sit, Phone Location: DominantWrist\n",
      "  Activity: walk, Phone Location: DominantWrist\n",
      "  Activity: upstairs, Phone Location: DominantWrist\n",
      "Train data: (220, 100, 6), Test data: (217, 100, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yuanh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 0.7453 | Train Acc: 57.27%\n",
      "Epoch 2/100 | Train Loss: 0.2115 | Train Acc: 95.45%\n",
      "Epoch 3/100 | Train Loss: 0.0857 | Train Acc: 97.27%\n",
      "Epoch 4/100 | Train Loss: 0.0184 | Train Acc: 99.55%\n",
      "Epoch 5/100 | Train Loss: 0.0060 | Train Acc: 100.00%\n",
      "Epoch 6/100 | Train Loss: 0.0277 | Train Acc: 99.09%\n",
      "Epoch 7/100 | Train Loss: 0.0035 | Train Acc: 100.00%\n",
      "Epoch 8/100 | Train Loss: 0.0212 | Train Acc: 99.09%\n",
      "Epoch 9/100 | Train Loss: 0.0244 | Train Acc: 98.64%\n",
      "Epoch 10/100 | Train Loss: 0.0422 | Train Acc: 98.64%\n",
      "Epoch 11/100 | Train Loss: 0.0150 | Train Acc: 99.55%\n",
      "Epoch 12/100 | Train Loss: 0.0212 | Train Acc: 99.09%\n",
      "Epoch 13/100 | Train Loss: 0.0095 | Train Acc: 99.55%\n",
      "Epoch 14/100 | Train Loss: 0.0173 | Train Acc: 99.55%\n",
      "Epoch 15/100 | Train Loss: 0.0097 | Train Acc: 99.55%\n",
      "Epoch 16/100 | Train Loss: 0.0015 | Train Acc: 100.00%\n",
      "Epoch 17/100 | Train Loss: 0.0013 | Train Acc: 100.00%\n",
      "Epoch 18/100 | Train Loss: 0.0023 | Train Acc: 100.00%\n",
      "Epoch 19/100 | Train Loss: 0.0018 | Train Acc: 100.00%\n",
      "Epoch 20/100 | Train Loss: 0.0015 | Train Acc: 100.00%\n",
      "Epoch 21/100 | Train Loss: 0.0017 | Train Acc: 100.00%\n",
      "Epoch 22/100 | Train Loss: 0.0010 | Train Acc: 100.00%\n",
      "Epoch 23/100 | Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Epoch 24/100 | Train Loss: 0.0010 | Train Acc: 100.00%\n",
      "Epoch 25/100 | Train Loss: 0.0009 | Train Acc: 100.00%\n",
      "Epoch 26/100 | Train Loss: 0.0011 | Train Acc: 100.00%\n",
      "Epoch 27/100 | Train Loss: 0.0009 | Train Acc: 100.00%\n",
      "Epoch 28/100 | Train Loss: 0.0008 | Train Acc: 100.00%\n",
      "Epoch 29/100 | Train Loss: 0.0008 | Train Acc: 100.00%\n",
      "Epoch 30/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Epoch 31/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Epoch 32/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Epoch 33/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 34/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Epoch 35/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Epoch 36/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Epoch 37/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 38/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 39/100 | Train Loss: 0.0007 | Train Acc: 100.00%\n",
      "Epoch 40/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 41/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 42/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 43/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 44/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 45/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 46/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 47/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 48/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 49/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 50/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 51/100 | Train Loss: 0.0006 | Train Acc: 100.00%\n",
      "Epoch 52/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 53/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 54/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 55/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 56/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 57/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 58/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 59/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 60/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 61/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 62/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 63/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 64/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 65/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 66/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 67/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 68/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 69/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 70/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 71/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 72/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 73/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 74/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 75/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 76/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 77/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 78/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 79/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 80/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 81/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 82/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 83/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 84/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 85/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 86/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 87/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 88/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 89/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 90/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 91/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 92/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 93/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 94/100 | Train Loss: 0.0005 | Train Acc: 100.00%\n",
      "Epoch 95/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 96/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 97/100 | Train Loss: 0.0008 | Train Acc: 100.00%\n",
      "Epoch 98/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 99/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "Epoch 100/100 | Train Loss: 0.0004 | Train Acc: 100.00%\n",
      "\n",
      "Test Accuracy (AfterTreatment): 53.00%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         sit       1.00      1.00      1.00        50\n",
      "        walk       0.00      0.00      0.00       102\n",
      "    upstairs       0.39      1.00      0.56        65\n",
      "\n",
      "    accuracy                           0.53       217\n",
      "   macro avg       0.46      0.67      0.52       217\n",
      "weighted avg       0.35      0.53      0.40       217\n",
      "\n",
      "Train-Test accuracy differs by 47.00%, which exceeds threshold of 35%. Data is different before vs after.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yuanh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\yuanh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\yuanh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_and_evaluate_before_after()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
